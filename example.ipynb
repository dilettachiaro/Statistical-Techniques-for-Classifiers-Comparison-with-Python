{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical Techniques for Classifiers Comparison withÂ Python"
      ],
      "metadata": {
        "id": "uxZjOLnwtUyg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xnkS9xxVpEqx"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pd.read_csv(url, names=names)\n",
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n"
      ],
      "metadata": {
        "id": "yUzljtIGtTyO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the  data\n",
        "train, test, train_labels, test_labels = train_test_split(X, Y, test_size=0.10,\n",
        "                                                          random_state=42, stratify = Y)"
      ],
      "metadata": {
        "id": "Nq8aDetNuRK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare models\n",
        "models = []\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('SVM', SVC()))\n"
      ],
      "metadata": {
        "id": "8sznihRFtr7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "for name, model in models:\n",
        "    model.fit(train, train_labels)\n",
        "    names.append(name)\n",
        "\n"
      ],
      "metadata": {
        "id": "zZjoPLkNvzCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = []\n",
        "for i in range(len(models)):\n",
        "    for j in range(i+1, len(models)):\n",
        "        print(names[i], names[j])\n",
        "        print(pd.crosstab(models[i][1].predict(test), models[j][1].predict(test), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
        "        print('\\n')\n",
        "        ct.append(pd.crosstab(models[i][1].predict(test), models[j][1].predict(test), rownames=['Actual'], colnames=['Predicted'], margins=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKqdIRBiwe6Q",
        "outputId": "6ed997bd-9f50-4997-fc78-8522c5597956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CART SVM\n",
            "Predicted  0.0  1.0  All\n",
            "Actual                  \n",
            "0.0         45    9   54\n",
            "1.0         12   11   23\n",
            "All         57   20   77\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctab = ct[0].iloc[:-1,:-1]\n",
        "contingency_table = ctab.copy()"
      ],
      "metadata": {
        "id": "zuGGyw49wQWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "def apply_sweep(x, MARGIN, FUN=np.subtract, STATS=None, check_margin=True, **kwargs):\n",
        "    '''\n",
        "    A Python version of the R function apply_sweep() from the basic R syntax.\n",
        "    The sweep R function applies an operation (e.g. + or -) to a data matrix by row or by column.\n",
        "\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------\n",
        "    x: Typically a matrix.\n",
        "    MARGIN: Specifies typically whether the operation should be applied by row or by column. MARGIN = 1 operates by row; MARGIN = 2 operates by column.\n",
        "    STATS: Specifies usually the value that should be used for the operation (e.g. the value that should be added or subtracted).\n",
        "    FUN: The operation that should be carried out (e.g. + or -).\n",
        "\n",
        "    Returns:\n",
        "    -----------------------\n",
        "    A matrix with the same dimensions as x with the operation applied by row or by column.\n",
        "    '''\n",
        "\n",
        "    if STATS is None:\n",
        "        STATS = np.array([], dtype=x.dtype)\n",
        "\n",
        "    dims = np.shape(x)\n",
        "\n",
        "    if isinstance(MARGIN, str):\n",
        "        dn = np.array(x).dtype.names\n",
        "\n",
        "        if dn is None:\n",
        "            raise ValueError(\"'x' must have named dimnames\")\n",
        "\n",
        "        MARGIN = np.where(dn == MARGIN)[0][0]\n",
        "\n",
        "        if np.any(np.isnan(MARGIN)):\n",
        "            raise ValueError(\"not all elements of 'MARGIN' are names of dimensions\")\n",
        "\n",
        "    if check_margin:\n",
        "        dimmargin = dims[MARGIN]\n",
        "        dimstats = pd.DataFrame(STATS).shape\n",
        "        lstats = np.size(STATS)\n",
        "\n",
        "        if lstats > np.prod(dimmargin):\n",
        "            print(\"Warning: STATS is longer than the extent of 'dim(x)[MARGIN]'\")\n",
        "        elif len(dimstats) == 0:\n",
        "            cumDim = np.append(1, np.cumprod(dimmargin))\n",
        "            upper = np.min(cumDim[cumDim >= lstats])\n",
        "            lower = np.max(cumDim[cumDim <= lstats])\n",
        "\n",
        "            if lstats and (upper % lstats != 0 or lstats % lower != 0):\n",
        "                print(\"Warning: STATS does not recycle exactly across MARGIN\")\n",
        "        else:\n",
        "            dimmargin = np.array(dimmargin).reshape(-1)\n",
        "            dimstats = np.array(dimstats)[:-1]\n",
        "\n",
        "            if len(dimstats) != len(dimmargin) or not np.any(dimstats == dimmargin):\n",
        "                print(\"Warning: length(STATS) or dim(STATS) do not match dim(x)[MARGIN]\")\n",
        "\n",
        "    perm = np.concatenate((np.arange(MARGIN), np.arange(MARGIN+1, len(dims)), [MARGIN]))\n",
        "    return FUN(x, STATS).transpose(perm).T\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "# KOHEN'S KAPPA\n",
        "\n",
        "def kappa(x, weights=['Equal-Spacing', 'Fleiss-Cohen']):\n",
        "    '''\n",
        "    Computes two agreement rates: Cohen's kappa and weighted kappa, and confidence bands.\n",
        "    A Python version of the R function Kappa() from the vcd package.\n",
        "\n",
        "    Parameters:\n",
        "    -----------------------\n",
        "    x: array_like or pandas.DataFrame\n",
        "        If `x` is a matrix, it should be a KxK matrix of counts of\n",
        "        assignments of objects to K categories.\n",
        "    weights:veither one of the character strings given in the default value, or a user-specified matrix with same dimensions as x.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    -----------------------\n",
        "    A dictionary containing the following:\n",
        "    - 'Unweighted': numeric vector of length 2 with the kappa statistic (value component), along with Approximate Standard Error (ASE component).\n",
        "    - 'Weighted': idem for the weighted kappa.\n",
        "    - 'CI': matrix with lower and upper bounds of the 95% confidence interval for the unweighted and weighted kappa.\n",
        "\n",
        "    '''\n",
        "    if isinstance(weights, str):\n",
        "        weights = [weights]\n",
        "    d = np.diag(x)\n",
        "    n = np.sum(x).sum()\n",
        "    nc = x.shape[1]\n",
        "    colFreqs = np.sum(x, axis=0)/n\n",
        "    rowFreqs = np.sum(x, axis=1)/n\n",
        "\n",
        "    def kappa_val(po, pc):\n",
        "        return (po - pc)/(1 - pc)\n",
        "    def std(p, pc, kw, W=None):\n",
        "        dot1 = np.dot(W, np.sum(p, axis=0))\n",
        "        dot2 = np.dot(W, np.sum(p, axis=1) * (1 - kw))\n",
        "        inner1 = np.inner(1, 1-pc)\n",
        "        inner2 = np.inner(1-pc, 1)\n",
        "        sweep1 = apply_sweep( W, MARGIN = 1, STATS = dot1 * (1 - kw))\n",
        "        return  np.sqrt(((np.sum(p * apply_sweep(sweep1, MARGIN=0, STATS = dot2)**2)).sum()- (kw - pc * (1 - kw)) **2) /(inner1 * inner2)/n)\n",
        "\n",
        "    # unweighted kappa\n",
        "    po = np.sum(d)/n\n",
        "    pc = np.inner(colFreqs, rowFreqs)\n",
        "    k = kappa_val(po, pc)\n",
        "    W0 = np.diag(np.ones(nc))\n",
        "    s = std(x/n, pc, k, W0)\n",
        "\n",
        "    # weighted kappa\n",
        "    if isinstance(weights, list):\n",
        "        if weights[0] == 'Equal-Spacing':\n",
        "            W = 1 - np.abs(np.subtract.outer(np.arange(1, nc+1), np.arange(1, nc+1)))/(nc-1)\n",
        "        else:\n",
        "            W = 1 - np.power(np.abs(np.subtract.outer(np.arange(1, nc+1), np.arange(1, nc+1)))/(nc-1), 2)\n",
        "    else:\n",
        "        W = weights\n",
        "\n",
        "    pow = np.sum(W * x).sum()/n\n",
        "    pcw = np.sum(W * np.outer(colFreqs, rowFreqs))\n",
        "    kw = kappa_val(pow, pcw)\n",
        "    sw = std(x/n, pcw, kw, W)\n",
        "\n",
        "    #compute z-score and p-value\n",
        "    # tab <- rbind(x$Unweighted, x$Weighted)\n",
        "    tab = np.vstack((np.array([k, s]), np.array([kw, sw])))\n",
        "    z = tab[:,0] / tab[:,1]\n",
        "    # tab <- cbind(tab, z, `Pr(>|z|)` = 2 * pnorm(-abs(z)))\n",
        "    tab = np.c_[tab, z, 2 * norm.cdf(-abs(z))]\n",
        "\n",
        "    CI = True\n",
        "    if CI:\n",
        "        level = 0.95\n",
        "        q = norm.ppf((1 + level)/2)\n",
        "        lower = tab[:,1] - q * tab[:,2]\n",
        "        upper = tab[:,1] + q * tab[:,2]\n",
        "        tab_ci = np.c_[tab, lower, upper]\n",
        "\n",
        "\n",
        "    return {'Unweighted': {'kappa': k, 'std': s, 'z': z[0], 'p': tab[0,3]},\n",
        "            'Weighted': {'kappa': kw, 'std': sw, 'z': z[1], 'p': tab[1,3]},\n",
        "            'CI': {'lower': lower, 'upper': upper}}\n",
        "\n",
        "\n",
        "# STUART-MAXWELL TEST\n",
        "\n",
        "def StuartMaxwellTest(x, y=None, BhapkarTest=False):\n",
        "    \"\"\"\n",
        "    Stuart-Maxwell test for marginal homogeneity of a KxK matrix of assignments\n",
        "    of objects to K categories or an nx2 or 2xn matrix of category scores for n\n",
        "    data objects by two raters. The statistic is distributed as Chi-square with\n",
        "    K-1 degrees of freedom.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    x : array_like or pandas.DataFrame\n",
        "        If `x` is a matrix, it should be a KxK matrix of counts of\n",
        "        assignments of objects to K categories.\n",
        "    y : array_like, optional\n",
        "        If `x` is a data frame, `y` should not be provided. Otherwise,\n",
        "        `y` should be a KxK matrix with the same counts as `x`.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    result : dict\n",
        "        A dictionary containing the following:\n",
        "        - 'method': str, the name of the test\n",
        "        - 'data.name': str, the name of the data\n",
        "        - 'statistic': float, the test statistic\n",
        "        - 'parameter': int, the degrees of freedom\n",
        "        - 'p.value': float, the p-value of the test\n",
        "        - 'N': int, the total number of observations\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(x, np.ndarray or pd.DataFrame):\n",
        "        r = x.shape[0]\n",
        "        if r < 2 or x.shape[1] != r:\n",
        "            raise ValueError(\"'x' must be square with at least two rows and columns\")\n",
        "        if (x < 0).any().any() or np.isnan(x).any().any():\n",
        "            raise ValueError(\"all entries of 'x' must be nonnegative and finite\")\n",
        "        DNAME = \"x\"\n",
        "    else:\n",
        "        if y is None:\n",
        "            raise ValueError(\"if 'x' is not a matrix, 'y' must be given\")\n",
        "        if y is not None and not isinstance(y, np.ndarray or pd.DataFrame):\n",
        "            raise TypeError(\"'y' must be a matrix\")\n",
        "        if len(x) != len(y):\n",
        "            raise ValueError(\"'x' and 'y' must have the same length\")\n",
        "        DNAME = \" and \".join([str(x), str(y)])\n",
        "        OK = np.logical_and(~np.isnan(x), ~np.isnan(y))\n",
        "        x = np.asarray(x, dtype=np.int64)[OK]\n",
        "        y = np.asarray(y, dtype=np.int64)[OK]\n",
        "        r = np.unique(x).shape[0]\n",
        "        if r < 2 or np.unique(y).shape[0] != r:\n",
        "            raise ValueError(\"'x' and 'y' must have the same number of levels (minimum 2)\")\n",
        "        x = np.asarray(np.histogram2d(x, y, bins=r)[0], dtype=np.int64)\n",
        "\n",
        "    # get the marginals\n",
        "    rowsums = x.sum(axis=1)\n",
        "    colsums = x.sum(axis=0)\n",
        "    #  If you have perfect agreement then you want something along the lines of:\n",
        "    equalsums_rows = np.diag(x) == rowsums\n",
        "    equalsums_cols = np.diag(x) == colsums\n",
        "\n",
        "    equalsums = np.logical_and(equalsums_rows, equalsums_cols)\n",
        "\n",
        "    if equalsums.any():\n",
        "        # dump any categories with perfect agreement\n",
        "        x = x[~equalsums][:, ~equalsums]\n",
        "        # bail out if too many categories have disappeared\n",
        "        if x.shape[0] < 2:\n",
        "            raise ValueError(\"Too many equal marginals, cannot compute\")\n",
        "        # get new marginals\n",
        "        rowsums = x.sum(axis=1)\n",
        "        colsums = x.sum(axis=0)\n",
        "\n",
        "    # use K-1 marginals\n",
        "    Kminus1 = rowsums.shape[0] - 1\n",
        "    smd = rowsums[:-1] - colsums[:-1]\n",
        "    smS = np.zeros((Kminus1, Kminus1))\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = pd.DataFrame(x)\n",
        "    for i in range(Kminus1):\n",
        "        for j in range(Kminus1):\n",
        "            if i == j:\n",
        "                smS[i,j] = rowsums[i] + colsums[j] - 2 * x.iloc[i,i]\n",
        "            else:\n",
        "                smS[i,j] = -(x.iloc[i,j] + x.iloc[j,i])\n",
        "\n",
        "    N = rowsums.sum()\n",
        "\n",
        "    if BhapkarTest == False:\n",
        "        STATISTIC = smd @ np.linalg.inv(smS) @ smd\n",
        "        PARAMETER = r - 1\n",
        "        METHOD = \"Stuart-Maxwell test\"\n",
        "        # PVAL = stats.chi2.sf(STATISTIC, PARAMETER)\n",
        "        PVAL = stats.chi2.sf(STATISTIC, PARAMETER)\n",
        "\n",
        "    elif BhapkarTest == True:\n",
        "        STATISTIC_pre = smd @ np.linalg.inv(smS) @ smd\n",
        "        STATISTIC = STATISTIC_pre / ( 1- STATISTIC_pre / N)\n",
        "        PARAMETER = r - 1\n",
        "        METHOD = \"Bhapkar test\"\n",
        "        PVAL = stats.chi2.sf(STATISTIC, PARAMETER)\n",
        "\n",
        "\n",
        "    RVAL = {\"statistic\": STATISTIC, \"parameter/dof\": PARAMETER,\n",
        "            \"p.value\": PVAL, \"method\": METHOD, \"data.name\": DNAME,\n",
        "            \"N\": N}\n",
        "    return RVAL\n"
      ],
      "metadata": {
        "id": "bwyDMud15lWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Kohen's K\n",
        "KAPPA = kappa(contingency_table)\n",
        "print(KAPPA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEAKXS9r5hro",
        "outputId": "2a76b9f1-0db2-43d6-9b32-35509d09333e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Unweighted': {'kappa': 0.3237139272271016, 'std': 0.11748990079336818, 'z': 2.7552489621761085, 'p': 0.005864749060470447}, 'Weighted': {'kappa': 0.3237139272271016, 'std': 0.11748990079336818, 'z': 2.7552489621761085, 'p': 0.005864749060470447}, 'CI': {'lower': array([-5.28269883, -5.28269883]), 'upper': array([5.51767864, 5.51767864])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table = contingency_table.to_numpy()\n",
        "# Stuart-Maxwell test\n",
        "SM = StuartMaxwellTest(contingency_table, BhapkarTest=False)\n",
        "print(SM)\n",
        "# Bhapkar test\n",
        "BP = StuartMaxwellTest(contingency_table, BhapkarTest=True)\n",
        "print(BP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STTLM_fi_dsm",
        "outputId": "f22f2b42-3536-4c1e-ed71-733efc694048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'statistic': 0.42857142857142855, 'parameter/dof': 1, 'p.value': 0.5126907602619235, 'method': 'Stuart-Maxwell test', 'data.name': 'x', 'N': 77}\n",
            "{'statistic': 0.43097014925373134, 'parameter/dof': 1, 'p.value': 0.5115132943916072, 'method': 'Bhapkar test', 'data.name': 'x', 'N': 77}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(contingency_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uu-cnLsADxZ",
        "outputId": "5a4cc4c9-9a3a-4ca4-8d58-77753236763f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 39]\n",
            " [19 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify values to get significant p-values\n",
        "contingency_table[0,0] = contingency_table[0,0] - 40\n",
        "contingency_table[0,1] = contingency_table[0,1]+30\n",
        "contingency_table[1,0] = contingency_table[1,0]+7\n",
        "contingency_table[1,1] = contingency_table[1,1]+3\n"
      ],
      "metadata": {
        "id": "zviV4Wou_6VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KAPPA2 = kappa(contingency_table)\n",
        "print(KAPPA2)\n",
        "SM2 = StuartMaxwellTest(contingency_table, BhapkarTest=False)\n",
        "print(SM2)\n",
        "BP2 = StuartMaxwellTest(contingency_table, BhapkarTest=True)\n",
        "print(BP2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr5Wj6Ry_m55",
        "outputId": "cceec737-6383-4aca-9f3d-03d9c93d0f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Unweighted': {'kappa': -0.42957746478873227, 'std': 0.09997763835232196, 'z': -4.296735468734498, 'p': 1.7333183398062133e-05}, 'Weighted': {'kappa': -0.42957746478873227, 'std': 0.09997763835232196, 'z': -4.296735468734498, 'p': 1.7333183398062133e-05}, 'CI': {'lower': array([8.52142441, 8.52142441]), 'upper': array([-8.32146913, -8.32146913])}}\n",
            "{'statistic': 6.8965517241379315, 'parameter/dof': 1, 'p.value': 0.008636216760319573, 'method': 'Stuart-Maxwell test', 'data.name': 'x', 'N': 77}\n",
            "{'statistic': 7.575012297097885, 'parameter/dof': 1, 'p.value': 0.005918297615044397, 'method': 'Bhapkar test', 'data.name': 'x', 'N': 77}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsqOK2t4AOgU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
