# -*- coding: utf-8 -*-
"""Statistical Techniques for Classifiers Comparison with Python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H5N31cr55KMhHrM2jsYKwr9ig6QbjC-j

# Statistical Techniques for Classifiers Comparison with Python
"""

# Import libraries
import pandas as pd
import numpy as np
from scipy.stats import norm
from scipy import stats
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC




def apply_sweep(x, MARGIN, FUN=np.subtract, STATS=None, check_margin=True, **kwargs):
    '''
    A Python version of the R function apply_sweep() from the basic R syntax.
    The sweep R function applies an operation (e.g. + or -) to a data matrix by row or by column.


    Parameters:
    -----------------------
    x: Typically a matrix.
    MARGIN: Specifies typically whether the operation should be applied by row or by column. MARGIN = 1 operates by row; MARGIN = 2 operates by column.
    STATS: Specifies usually the value that should be used for the operation (e.g. the value that should be added or subtracted).
    FUN: The operation that should be carried out (e.g. + or -).

    Returns:
    -----------------------
    A matrix with the same dimensions as x with the operation applied by row or by column.
    '''

    if STATS is None:
        STATS = np.array([], dtype=x.dtype)

    dims = np.shape(x)

    if isinstance(MARGIN, str):
        dn = np.array(x).dtype.names

        if dn is None:
            raise ValueError("'x' must have named dimnames")

        MARGIN = np.where(dn == MARGIN)[0][0]

        if np.any(np.isnan(MARGIN)):
            raise ValueError("not all elements of 'MARGIN' are names of dimensions")

    if check_margin:
        dimmargin = dims[MARGIN]
        dimstats = pd.DataFrame(STATS).shape
        lstats = np.size(STATS)

        if lstats > np.prod(dimmargin):
            print("Warning: STATS is longer than the extent of 'dim(x)[MARGIN]'")
        elif len(dimstats) == 0:
            cumDim = np.append(1, np.cumprod(dimmargin))
            upper = np.min(cumDim[cumDim >= lstats])
            lower = np.max(cumDim[cumDim <= lstats])

            if lstats and (upper % lstats != 0 or lstats % lower != 0):
                print("Warning: STATS does not recycle exactly across MARGIN")
        else:
            dimmargin = np.array(dimmargin).reshape(-1)
            dimstats = np.array(dimstats)[:-1]

            if len(dimstats) != len(dimmargin) or not np.any(dimstats == dimmargin):
                print("Warning: length(STATS) or dim(STATS) do not match dim(x)[MARGIN]")

    perm = np.concatenate((np.arange(MARGIN), np.arange(MARGIN+1, len(dims)), [MARGIN]))
    return FUN(x, STATS).transpose(perm).T




# %%
# KOHEN'S KAPPA

def kappa(x, weights=['Equal-Spacing', 'Fleiss-Cohen']):
    '''
    Computes two agreement rates: Cohen's kappa and weighted kappa, and confidence bands.
    A Python version of the R function Kappa() from the vcd package.

    Parameters:
    -----------------------
    x: array_like or pandas.DataFrame
        If `x` is a matrix, it should be a KxK matrix of counts of
        assignments of objects to K categories.
    weights:veither one of the character strings given in the default value, or a user-specified matrix with same dimensions as x.


    Returns:
    -----------------------
    A dictionary containing the following:
    - 'Unweighted': numeric vector of length 2 with the kappa statistic (value component), along with Approximate Standard Error (ASE component).
    - 'Weighted': idem for the weighted kappa.
    - 'CI': matrix with lower and upper bounds of the 95% confidence interval for the unweighted and weighted kappa.

    '''
    if isinstance(weights, str):
        weights = [weights]
    d = np.diag(x)
    n = np.sum(x).sum()
    nc = x.shape[1]
    colFreqs = np.sum(x, axis=0)/n
    rowFreqs = np.sum(x, axis=1)/n

    def kappa_val(po, pc):
        return (po - pc)/(1 - pc)
    def std(p, pc, kw, W=None):
        dot1 = np.dot(W, np.sum(p, axis=0))
        dot2 = np.dot(W, np.sum(p, axis=1) * (1 - kw))
        inner1 = np.inner(1, 1-pc)
        inner2 = np.inner(1-pc, 1)
        sweep1 = apply_sweep( W, MARGIN = 1, STATS = dot1 * (1 - kw))
        return  np.sqrt(((np.sum(p * apply_sweep(sweep1, MARGIN=0, STATS = dot2)**2)).sum()- (kw - pc * (1 - kw)) **2) /(inner1 * inner2)/n)

    # unweighted kappa
    po = np.sum(d)/n
    pc = np.inner(colFreqs, rowFreqs)
    k = kappa_val(po, pc)
    W0 = np.diag(np.ones(nc))
    s = std(x/n, pc, k, W0)

    # weighted kappa
    if isinstance(weights, list):
        if weights[0] == 'Equal-Spacing':
            W = 1 - np.abs(np.subtract.outer(np.arange(1, nc+1), np.arange(1, nc+1)))/(nc-1)
        else:
            W = 1 - np.power(np.abs(np.subtract.outer(np.arange(1, nc+1), np.arange(1, nc+1)))/(nc-1), 2)
    else:
        W = weights

    pow = np.sum(W * x).sum()/n
    pcw = np.sum(W * np.outer(colFreqs, rowFreqs))
    kw = kappa_val(pow, pcw)
    sw = std(x/n, pcw, kw, W)

    #compute z-score and p-value
    # tab <- rbind(x$Unweighted, x$Weighted)
    tab = np.vstack((np.array([k, s]), np.array([kw, sw])))
    z = tab[:,0] / tab[:,1]
    # tab <- cbind(tab, z, `Pr(>|z|)` = 2 * pnorm(-abs(z)))
    tab = np.c_[tab, z, 2 * norm.cdf(-abs(z))]

    CI = True
    if CI:
        level = 0.95
        q = norm.ppf((1 + level)/2)
        lower = tab[:,1] - q * tab[:,2]
        upper = tab[:,1] + q * tab[:,2]
        tab_ci = np.c_[tab, lower, upper]


    return {'Unweighted': {'kappa': k, 'std': s, 'z': z[0], 'p': tab[0,3]},
            'Weighted': {'kappa': kw, 'std': sw, 'z': z[1], 'p': tab[1,3]},
            'CI': {'lower': lower, 'upper': upper}}


# STUART-MAXWELL TEST
def StuartMaxwellTest(x, y=None, BhapkarTest=False):
    """
    Stuart-Maxwell test for marginal homogeneity of a KxK matrix of assignments
    of objects to K categories or an nx2 or 2xn matrix of category scores for n
    data objects by two raters. The statistic is distributed as Chi-square with
    K-1 degrees of freedom.

    Parameters:
    -----------
    x : array_like or pandas.DataFrame
        If `x` is a matrix, it should be a KxK matrix of counts of
        assignments of objects to K categories.
    y : array_like, optional
        If `x` is a data frame, `y` should not be provided. Otherwise,
        `y` should be a KxK matrix with the same counts as `x`.

    Returns:
    --------
    result : dict
        A dictionary containing the following:
        - 'method': str, the name of the test
        - 'data.name': str, the name of the data
        - 'statistic': float, the test statistic
        - 'parameter': int, the degrees of freedom
        - 'p.value': float, the p-value of the test
        - 'N': int, the total number of observations
    """

    if isinstance(x, np.ndarray or pd.DataFrame):
        r = x.shape[0]
        if r < 2 or x.shape[1] != r:
            raise ValueError("'x' must be square with at least two rows and columns")
        if (x < 0).any().any() or np.isnan(x).any().any():
            raise ValueError("all entries of 'x' must be nonnegative and finite")
        DNAME = "x"
    else:
        if y is None:
            raise ValueError("if 'x' is not a matrix, 'y' must be given")
        if y is not None and not isinstance(y, np.ndarray or pd.DataFrame):
            raise TypeError("'y' must be a matrix")
        if len(x) != len(y):
            raise ValueError("'x' and 'y' must have the same length")
        DNAME = " and ".join([str(x), str(y)])
        OK = np.logical_and(~np.isnan(x), ~np.isnan(y))
        x = np.asarray(x, dtype=np.int64)[OK]
        y = np.asarray(y, dtype=np.int64)[OK]
        r = np.unique(x).shape[0]
        if r < 2 or np.unique(y).shape[0] != r:
            raise ValueError("'x' and 'y' must have the same number of levels (minimum 2)")
        x = np.asarray(np.histogram2d(x, y, bins=r)[0], dtype=np.int64)

    # get the marginals
    rowsums = x.sum(axis=1)
    colsums = x.sum(axis=0)
    #  If you have perfect agreement then you want something along the lines of:
    equalsums_rows = np.diag(x) == rowsums
    equalsums_cols = np.diag(x) == colsums

    equalsums = np.logical_and(equalsums_rows, equalsums_cols)

    if equalsums.any():
        # dump any categories with perfect agreement
        x = x[~equalsums][:, ~equalsums]
        # bail out if too many categories have disappeared
        if x.shape[0] < 2:
            raise ValueError("Too many equal marginals, cannot compute")
        # get new marginals
        rowsums = x.sum(axis=1)
        colsums = x.sum(axis=0)

    # use K-1 marginals
    Kminus1 = rowsums.shape[0] - 1
    smd = rowsums[:-1] - colsums[:-1]
    smS = np.zeros((Kminus1, Kminus1))
    if isinstance(x, np.ndarray):
        x = pd.DataFrame(x)
    for i in range(Kminus1):
        for j in range(Kminus1):
            if i == j:
                smS[i,j] = rowsums[i] + colsums[j] - 2 * x.iloc[i,i]
            else:
                smS[i,j] = -(x.iloc[i,j] + x.iloc[j,i])

    N = rowsums.sum()

    if BhapkarTest == False:
        STATISTIC = smd @ np.linalg.inv(smS) @ smd
        PARAMETER = r - 1
        METHOD = "Stuart-Maxwell test"
        # PVAL = stats.chi2.sf(STATISTIC, PARAMETER)
        PVAL = stats.chi2.sf(STATISTIC, PARAMETER)

    elif BhapkarTest == True:
        STATISTIC_pre = smd @ np.linalg.inv(smS) @ smd
        STATISTIC = STATISTIC_pre / ( 1- STATISTIC_pre / N)
        PARAMETER = r - 1
        METHOD = "Bhapkar test"
        PVAL = stats.chi2.sf(STATISTIC, PARAMETER)


    RVAL = {"statistic": STATISTIC, "parameter/dof": PARAMETER,
            "p.value": PVAL, "method": METHOD, "data.name": DNAME,
            "N": N}
    return RVAL
